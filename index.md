# SIGDIAL 2018 Special Session on Conversational Approaches to Information Search, Retrievals, and Presentation

## Overview

While information search via modern search engines represents one of the great technology contributions of the past twenty years, complex information search, particularly over unstructured text and non-textual information (e.g., images), poses challenges for speech-only interfaces. In particular, processing long lists of information akin to a list of search results is cognitively demanding and simple rendering of search engine result lists via speech has been shown to be ineffective from a HCI perspective, and it has been suggested that approaches supporting greater interactivity via spoken dialogue present greater promise. The special session will create a forum to present and plan research directions on conversational approaches to Information Search. A specific focus is on techniques that support complex and multi-turn user-machine dialogues for information access and retrieval, and spoken and multi-modal interfaces for interacting with such systems. We invite submissions addressing all modalities of conversation, including speech-based, text-based, and multimodal interaction. We also welcome studies of human-human interaction (e.g., collaborative search) that can inform the design of conversational search applications, as well as work on evaluation of conversational approaches to information search.

### Motivation

Recent advances in automatic speech recognition (ASR) technologies have changed the way people seek information and interact with devices. For example, search engine companies report that approximately 20% of mobile queries are now via speech inputs from mobile devices. Services such as Apple Siri and Google Assistant enable users to find information using naturally spoken questions rather than conventional keywords. In addition, products such as Amazon Echo and Google Home have extended the context of speech oriented interaction from mobile to office and home. These technologies are currently designed to answer well formulated queries, questions, or commands.

However, search engines have been effective at retrieving relevant information for ill-defined, poorly expressed information needs, which is not yet achieved by existing speech-based applications. A report from SWIRL 2012 also identified conversational approaches to IR as one of the most important directions in Information Retrieval. Moreover, work evaluating spoken interfaces to search engines demonstrate that replicating the standard approach to listing results is ineffective over a speech-only channel. Therefore, the new ways of speech-based access to search offers many opportunities and challenges in Information Retrieval to make search interactions more conversational, and to develop innovative search applications.

### Theme and Purpose

Recent advances in automatic speech recognition (ASR) technologies have changed the way people seek information and interact with devices. For example, search engine companies report that approximately 20% of mobile queries are now via speech inputs from mobile devices. Services such as Apple Siri and Google Assistant enable users to find information using naturally spoken questions rather than conventional keywords. In addition, products such as Amazon Echo and Google Home have extended the context of speech oriented interaction from mobile to office and home. These technologies are currently designed to answer well formulated queries, questions, or commands.

However, search engines have been effective at retrieving relevant information for ill-defined, poorly expressed information needs, which is not yet achieved by existing speech-based applications. A report from SWIRL 2012 also identified conversational approaches to IR as one of the most important directions in Information Retrieval. Moreover, work evaluating spoken interfaces to search engines demonstrate that replicating the standard approach to listing results is ineffective over a speech-only channel. Therefore, the new ways of speech-based access to search offers many opportunities and challenges in Information Retrieval to make search interactions more conversational, and to develop innovative search applications.

## Call for Papers

The special session will create a forum to present and plan research directions on conversational approaches to Information Search. A specific focus is on techniques that support complex and multi-turn user-machine dialogues for information access and retrieval, and spoken and multi-modal interfaces for interacting with such systems. We invite submissions addressing all modalities of conversation, including speech-based, text-based, and multimodal interaction. We also welcome studies of human-human interaction (e.g., collaborative search) that can inform the design of conversational search applications, as well as work on evaluation of conversational approaches to information search.

### Topics of Interest

The session welcomes a broad range of techniques and studies that can contribute to the understanding and development of conversational approaches to Information Retrieval. Potential topics include (but are not limited to):
 - User intent recognition and search process management.
    - Approaches to dialog management and dialog state tracking suitable for search
    - Processing verbose natural language queries / noisy ASR
    - Query intent disambiguation, clarification, confirmation
    - Succinct clarification strategies and directed feedback
    - Interaction patterns for conversational search
 - Search result presentation.
    - Language generation for appropriate descriptions of search results
    - Summarisation of long lists of search results from unstructured information
    - Conversational navigation of search results
 - Evaluation.
    - Building test collections for conversational search evaluation
    - Frameworks and metrics to measure effectiveness, engagement, and user satisfaction of conversational search systems 
 - Applications.
    - Intelligent digital assistants
    - Proactive search/recommendation
    - Collaborative search
    - Search for visually impaired users
    - Search for low literacy users
    - Integration with existing technologies
    
### Submissions
 - **Long papers and short papers** will present original research and go through the regular SIGIDAL peer review process by the general SIGdial program committee. These papers will appear in the main SIGDIAL proceedings and are presented with the main track. Long papers must be no longer than eight pages, including title, text, figures and tables, along with two additional pages for example discourses or dialogues and algorithms. Short papers should be no longer than four pages including title, text, figures and tables, along with one additional page for example discourses or dialogues and algorithms. An unlimited number of pages are allowed for references.

 - **Position papers** will showcase ongoing work and focused, relevant contributions. Submissions are limited to four pages including references. These will be reviewed by the special session organizers and posted on the special session website. These papers will be presented as lightning talks or posters during the session. Authors will retain the copyright to their work so that they may submit to other venues as their work matures.

**Multiple Submissions.** Papers that have been or will be submitted to other meetings or publications must provide this information (see submission link). SIGDIAL Special Sessions cannot accept work for publication or presentation that will be (or has been) published elsewhere. 
**Blind Review.** The Special Session will follow SIGDIAL 2018 policies for preserving the integrity of double blind review (see author guidelines). Unlike long and short papers, demo descriptions will not be anonymous. Demo descriptions should include the authors' names and affiliations, and self-references are allowed.
**Sumbission Format.** All long, short, and demonstration submissions must follow the two-column ACL 2018 format. Authors are expected to use the ACL LaTeX style template or Microsoft Word style template from the ACL 2018 conference. Submissions must conform to the official ACL 2018 style guidelines, which are contained in these templates. Submissions must be electronic, in PDF format.
Submission Link. To submit a long or short paper, please go to the SIGDIAL 2018 main page for conference submissions (**deadline March 11**). When submitting, indicate “Conversational Approaches to Information Search, Retrievals, and Presentation” as the candidate special session. All long and short submissions must follow the SIGDIAL 2018 format. To submit a position paper, please submit by emailing cairdial@googlegroups.com by **April 28**.

## Important Dates

 - Long and short papers deadline: **March 11, 2018**
 - Position papers deadline: **April 28, 2018**
 - Special Session at SIGDIAL 2018: **uly 12-14, 2018**

## Session Committee

 - [Lawrence Cavedon](http://goanna.cs.rmit.edu.au/~lcavedon/), RMIT University (primary contact)
 - [Hideo Joho](http://www.slis.tsukuba.ac.jp/~hideo/), Univerity of Tsukuba
 - [Filip Radlinksi](http://www.radlinski.org/), Google London
 - [Hanna Silen](https://scholar.google.fi/citations?user=2eJmg08AAAAJ&hl=en), Google Zurich
 - [Damiano Spina](http://www.damianospina.com), RMIT University
 - [Johanne Trippas](http://johannetrippas.com/), RMIT University
 - [Jason Williams](https://www.microsoft.com/en-us/research/people/jawillia/), Microsoft Research
 
 

